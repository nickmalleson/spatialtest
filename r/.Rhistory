c('Mean','Confidence intervals'),  pch=16, col=c("black","grey"), cex=0.8)
# Upper confidence interval first
plot(
result$conf.upper, result$base,
pch = 16, col = "dark grey",cex = 0.5,xlab = "Bootstrap Estimates",ylab = "Observed Count"
#main="The mean and confidence interval for each area in the base data set"
)
# Lower confidence interval
points(result$conf.lower, result$base,pch = 16,col = "dark grey",cex = 0.5)
# Mean
points(result@data$mean, result$base, pch = 16,col = "black",cex = 0.5)
# Test data - blue for within intervals, red outside
points(
result$test, result$base, pch = 16, cex = 0.5,
col=ifelse(result$test<monte.carlo[(N + 3),] | result$test>monte.carlo[(N + 2),], "red", "green")
)
legend(x=0, y=max(result$base),
c('Mean','Confidence intervals', 'Test value within intervals', 'Test value outside intervals'),
pch=16, col=c("black","grey","blue", "green"), cex=0.8)
# Upper confidence interval first
plot(
result$conf.upper, result$base,
pch = 16, col = "dark grey",cex = 0.5,xlab = "Bootstrap Estimates",ylab = "Observed Count"
#main="The mean and confidence interval for each area in the base data set"
)
# Lower confidence interval
points(result$conf.lower, result$base,pch = 16,col = "dark grey",cex = 0.5)
# Mean
points(result@data$mean, result$base, pch = 16,col = "black",cex = 0.5)
# Test data - blue for within intervals, red outside
points(
result$test, result$base, pch = 16, cex = 0.5,
col=ifelse(result$test<result$conf.upper | result$test>result$conf.lower, "red", "green")
)
legend(x=0, y=max(result$base),
c('Mean','Confidence intervals', 'Test value within intervals', 'Test value outside intervals'),
pch=16, col=c("black","grey","blue", "green"), cex=0.8)
# Upper confidence interval first
plot(
result$conf.upper, result$base,
pch = 16, col = "dark grey",cex = 0.5,xlab = "Bootstrap Estimates",ylab = "Observed Count"
#main="The mean and confidence interval for each area in the base data set"
)
# Lower confidence interval
points(result$conf.lower, result$base,pch = 16,col = "dark grey",cex = 0.5)
# Mean
points(result@data$mean, result$base, pch = 16,col = "black",cex = 0.5)
# Test data - blue for within intervals, red outside
points(
result$test, result$base, pch = 16, cex = 0.5,
col=ifelse(result$test<result$conf.upper | result$test>result$conf.lower, "red", "green")
)
legend(x=0, y=max(result$base),
c('Mean','Confidence intervals', 'Test value within intervals', 'Test value outside intervals'),
pch=16, col=c("black","grey","blue", "green"), cex=0.8)
#' Run Martin Andresen's Spatial Test
#'
#' @param basepoints The base point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param testpoints The test point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param areas The areas to aggregate the points to and run the test on. This is expected to be a SpatialPolygonsDataFrame.
#' @return The \code{areas} dataset with some new columns:
#'  Local.S - The S index for each area (either -1, 0, or 1)
#'   S - The global S index (which will be the same for each area)
#'   S.nozero - Same as 'S', but ignores areas without any crimes in them
#'   mean - The mean points in each area after resampling
#'   conf.upper - the Upper confidence interval for the test
#'   conf.lower <- The lower confidence interval for the test
#' @examples
#' spatialtest(base.data, test.data, areas)
spatialtest <- function(basepoints, testpoints, areas) {
# Aggregate the points to the area dataset
areas$base <- poly.counts(base.data, areas)
areas$test <- poly.counts(test.data,areas)
len <- length(areas) # The number of areas
tot <- sum(areas$base)    # The number of crimes
# An array to store the results of each monte carlo iteration temporarily.
# This is in long form (one row per crime). Dim 1=i, 2=sampled data (temp)
result <- array(0,c(2,tot))
# Generate the long form of the data for sampling - one row per crime
# (actually it's one crime per colum technically, but that doesn't really matter)
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
}
# Now run the Monte-Carlo simulation
# Store the results of each iteration in the monte.carlo array.
# N columns are for the simulations for each run, remaining three columns are for the mean
# of all runs and the upper and lower confidence intervals.
monte.carlo <- array(0,c((N + 3),len))
for (i in 1:N) { # (Could do this bit multi-process)
#resample (NOT SURE HOW THIS WORKS!!)
mc.samp <- trunc(runif(tot,min = 1,max = (tot + 1))) # Create a random number for each row
result[2,(1:tot)] <- result[1,mc.samp[1:tot]] # Store sampled data in result[2,] temporarily
for (j in 1:len) {
monte.carlo[i,j] <- sum(result[2,] == j) #compute reaggregate to areas
}
}
# Calculate the mean and confidence intervals for each area after the simulations
temp <- rep(0,N)
for (i in 1:len) {
monte.carlo[(N + 1),i] <- mean(monte.carlo[c(1:N),i])
temp[] <- sort(monte.carlo[c(1:N),i])
monte.carlo[(N + 2),i] <- temp[0.95 * N] #upper
monte.carlo[(N + 3),i] <- temp[0.05 * N] #lower
}
# Compute the local S index for each area.
# 0 if within confidence intervals, -1 or +1 otherwise
areas@data$Local.S <- ifelse(
areas$test <= monte.carlo[(N + 3),], -1,
ifelse( areas$test >= monte.carlo[(N + 2),], 1, 0 )
)
# Compute the global S Index
# Do this by adding up the number of times that the test data point is within the upper and lower bounds
# of the base data. (Could also do this using the local index calculated above)
S <-  sum(
(areas$test >= monte.carlo[(N + 3),]) & (areas$test <= monte.carlo[(N + 2),])
) / len
# Calculate excluding zero entries
# Same as above but also include the condition that there has to be a crime in the test data set
# as well as being within bounds.
S.nozero <- sum(
(areas$test >= monte.carlo[N + 3,]) & (areas$test <= monte.carlo[N + 2,]) & (areas$test > 0)
) / len
print(paste("S index: ",S, ". Excluding zeros: ",S.nozero))
# Store results ready to be returned when this is implemented as a function
areas@data$S = S # The s index, will be the same for each area (it is global)
areas@data$S.nozero = S.nozero
areas@data$mean <- monte.carlo[(N+1),1:len]       # Mean points in each area after resampling
areas@data$conf.upper <- monte.carlo[(N+2),1:len] # Upper confidence interval
areas@data$conf.lower <- monte.carlo[(N+3),1:len] # Lower confidence interval
areas@monte.carlo <- monte.carlo
return(areas)
}
result <- spatialtest(basepoints = base.data, testpoints = test.data, areas = areas)
?array
#' Run Martin Andresen's Spatial Test
#'
#' @param basepoints The base point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param testpoints The test point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param areas The areas to aggregate the points to and run the test on. This is expected to be a SpatialPolygonsDataFrame.
#' @param get.monte.carlo If true, then instead of returning the areas, return an array with the full results of all of the monte carlo runs in it. This is useful for debugging, or for plotting the results of each run. The array has N + 3 dimensions where N is the number of monte carlo iterations and the remaining three dimensions give the mean (N + 1), upper limit (N + 2), lower limit (N + 3).
#' @return The \code{areas} dataset with some new columns:
#'  Local.S - The S index for each area (either -1, 0, or 1)
#'   S - The global S index (which will be the same for each area)
#'   S.nozero - Same as 'S', but ignores areas without any crimes in them
#'   mean - The mean points in each area after resampling
#'   conf.upper - the Upper confidence interval for the test
#'   conf.lower - The lower confidence interval for the test
#' @examples
#' spatialtest(base.data, test.data, areas)
spatialtest <- function(basepoints, testpoints, areas, get.monte.carlo=FALSE) {
# Aggregate the points to the area dataset
areas$base <- poly.counts(base.data, areas)
areas$test <- poly.counts(test.data,areas)
len <- length(areas) # The number of areas
tot <- sum(areas$base)    # The number of crimes
# An array to store the results of each monte carlo iteration temporarily.
# This is in long form (one row per crime). Dim 1=i, 2=sampled data (temp)
result <- array(0,c(2,tot))
# Generate the long form of the data for sampling - one row per crime
# (actually it's one crime per colum technically, but that doesn't really matter)
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
}
# Now run the Monte-Carlo simulation
# Store the results of each iteration in the monte.carlo array.
# N columns are for the simulations for each run, remaining three columns are for the mean
# of all runs and the upper and lower confidence intervals.
monte.carlo <- array(0,c((N + 3),len))
for (i in 1:N) { # (Could do this bit multi-process)
#resample (NOT SURE HOW THIS WORKS!!)
mc.samp <- trunc(runif(tot,min = 1,max = (tot + 1))) # Create a random number for each row
result[2,(1:tot)] <- result[1,mc.samp[1:tot]] # Store sampled data in result[2,] temporarily
for (j in 1:len) {
monte.carlo[i,j] <- sum(result[2,] == j) #compute reaggregate to areas
}
}
# Calculate the mean and confidence intervals for each area after the simulations
temp <- rep(0,N)
for (i in 1:len) {
monte.carlo[(N + 1),i] <- mean(monte.carlo[c(1:N),i])
temp[] <- sort(monte.carlo[c(1:N),i])
monte.carlo[(N + 2),i] <- temp[0.95 * N] #upper
monte.carlo[(N + 3),i] <- temp[0.05 * N] #lower
}
# At this point we can just return the full monte carlo results if that's what the caller wants
if (get.monte.carlo) {
return(monte.carlo)
}
# Compute the local S index for each area.
# 0 if within confidence intervals, -1 or +1 otherwise
areas@data$Local.S <- ifelse(
areas$test <= monte.carlo[(N + 3),], -1,
ifelse( areas$test >= monte.carlo[(N + 2),], 1, 0 )
)
# Compute the global S Index
# Do this by adding up the number of times that the test data point is within the upper and lower bounds
# of the base data. (Could also do this using the local index calculated above)
S <-  sum(
(areas$test >= monte.carlo[(N + 3),]) & (areas$test <= monte.carlo[(N + 2),])
) / len
# Calculate excluding zero entries
# Same as above but also include the condition that there has to be a crime in the test data set
# as well as being within bounds.
S.nozero <- sum(
(areas$test >= monte.carlo[N + 3,]) & (areas$test <= monte.carlo[N + 2,]) & (areas$test > 0)
) / len
print(paste("S index: ",S, ". Excluding zeros: ",S.nozero))
# Store results ready to be returned when this is implemented as a function
areas@data$S = S # The s index, will be the same for each area (it is global)
areas@data$S.nozero = S.nozero
areas@data$mean <- monte.carlo[(N+1),1:len]       # Mean points in each area after resampling
areas@data$conf.upper <- monte.carlo[(N+2),1:len] # Upper confidence interval
areas@data$conf.lower <- monte.carlo[(N+3),1:len] # Lower confidence interval
return(areas)
}
result <- spatialtest(basepoints = base.data, testpoints = test.data, areas = areas)
typeof(areas)
typeof(areas) == "S4"
typeof(areas) == "S4D"
class(areas)
class(areas) == SpatialPolygonsDataFrame()
is(df,"data.frame")
is(areas,"SpatialPolygonsDataFrame")
is(c(1,2),"SpatialPolygonsDataFrame")
is(NULL,"SpatialPolygonsDataFrame")
if (TRUE) {}
class(c(2))
class(c(2,s))
class(c(2,"s"))
c(2,"d")
typeof(c(2,"d"))
c()
typeof("d")
typeof(vector())
typeof(vector(2,1))
typeof(list(2m1))
typeof(list(2.1))
typeof(list(2,1))
list(4.3)
list(4.3)[1.]
list(4.3)[1,]
list(4.3)[[1]]
list(4,3)[[1]]
list(4,3)[[2]]
is(list(4,3), "list")
is.list(4,3)
is.list(list(4,3))
is.list(c(3,3))
t <-base.data + test.data
t <- union(base.data, test.data)
t <- sp::union(base.data, test.data)
t <- gUnaryUnion(base.data, test.data)
t <- gUnion(base.data, test.data)
plot(base.data)
points(t, add=T, col="blue")
areas=list(20,30)
rast <- raster()
extent(rast) <- extent(gUnion(base.data, test.data)) # this might be unnecessary
rast <- raster()
setwd('~/research_not_syncd/git_projects/spatialtest/r/')
library(GISTools)
#library(rgeos)    # For things like gIntersects
library(rgdal)     # For reading shapefiles
library(raster)    # For creating regular grids
#library(plyr)     # For counting and aggregating
#library(tmap)     # For thematic maps
#library(classInt) # Jenks natural breaks
#library(png)      # For loading pngs after they have been written
#library(grid)     # so that they can be embedded in knitted documents
#library(spdep)    # For doing the spatial regression, contiguity matrices, etc.
#library(GWmodel)  # For geographically weighted regression (GWR)
#library(MASS)     # For stepwise regression (stepAIC())
#library(pander)   # For printing tables nicely
#library(MVN)      # For testing for multivariate normality (MVN)
rast <- raster()
extent(rast) <- extent(gUnion(base.data, test.data)) # this might be unnecessary
ncol(rast) <- areas[[1]]
nrow(rast) <- areas[[2]]
plot(rast)
SPDF = SpatialPolygonsDataFrame(rast, data.frame(), row.names = c())
SPDF = SpatialPolygonsDataFrame(rast)
spdf <- rasterToPolygons(raster)
spdf <- rasterToPolygons(rast)
plot(spdf, add=T)
#' Run Martin Andresen's Spatial Test
#'
#' @param basepoints The base point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param testpoints The test point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param areas The areas to aggregate the points to and run the test on. The type of this parameter changes the behaviour of the test:
#' - If a `SpatialPolygonsDataFrame` is provided, then the test will run using that geography (normal behaviour)
#' - If no `areas` parameter is provided, then the test will be run on a number of different regular grids of increasing size.
#' - If a list is provided, then the test will assume that this provides the number of cells across (columsm `areas[[1]]`) and down (rows, `areas[[2]]`) and will create a sigle regular grid that spans the extent of all of the input points with that many cells in it.
#' @param get.monte.carlo If true, then instead of returning the areas, return an array with the full results of all of the monte carlo runs in it. This is useful for debugging, or for plotting the results of each run. The array has N + 3 dimensions where N is the number of monte carlo iterations and the remaining three dimensions give the mean (N + 1), upper limit (N + 2), lower limit (N + 3).
#' @return The \code{areas} dataset with some new columns:
#'  Local.S - The S index for each area (either -1, 0, or 1)
#'   S - The global S index (which will be the same for each area)
#'   S.nozero - Same as 'S', but ignores areas without any crimes in them
#'   mean - The mean points in each area after resampling
#'   conf.upper - the Upper confidence interval for the test
#'   conf.lower - The lower confidence interval for the test
#' @examples
#' spatialtest(base.data, test.data, areas)
spatialtest <- function(basepoints, testpoints, areas, get.monte.carlo=FALSE) {
if (is(areas,"SpatialPolygonsDataFrame")) {
# The areas parameter is some polygons, so no need to do anything special.
# (This if statement could be removed, but is left here for clarity)
}
if (is.list(areas)) {
# The areas parameter is a list that provides the number of cells across and down. So now make a regular grid with these characteristics
# Make a raster first, then convert this to a SpatialPolygonsDataFrame
rast <- raster()
# Calculate extent of all the point (both crime and test data)
extent(rast) <- extent(gUnion(base.data, test.data))
# Now set the number of rows and columns
ncol(rast) <- areas[[1]]
nrow(rast) <- areas[[2]]
# Finish by converting to a SpatialPolygonsDataFrame
areas = SpatialPolygonsDataFrame(rast)
}
if (areas==NULL) {
# If areas is null the run the expanding cell algorithm
XXXX
}
# Aggregate the points to the area dataset
areas$base <- poly.counts(base.data, areas)
areas$test <- poly.counts(test.data,areas)
len <- length(areas) # The number of areas
tot <- sum(areas$base)    # The number of crimes
# An array to store the results of each monte carlo iteration temporarily.
# This is in long form (one row per crime). Dim 1=i, 2=sampled data (temp)
result <- array(0,c(2,tot))
# Generate the long form of the data for sampling - one row per crime
# (actually it's one crime per colum technically, but that doesn't really matter)
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
}
# Now run the Monte-Carlo simulation
# Store the results of each iteration in the monte.carlo array.
# N columns are for the simulations for each run, remaining three columns are for the mean
# of all runs and the upper and lower confidence intervals.
monte.carlo <- array(0,c((N + 3),len))
for (i in 1:N) { # (Could do this bit multi-process)
#resample (NOT SURE HOW THIS WORKS!!)
mc.samp <- trunc(runif(tot,min = 1,max = (tot + 1))) # Create a random number for each row
result[2,(1:tot)] <- result[1,mc.samp[1:tot]] # Store sampled data in result[2,] temporarily
for (j in 1:len) {
monte.carlo[i,j] <- sum(result[2,] == j) #compute reaggregate to areas
}
}
# Calculate the mean and confidence intervals for each area after the simulations
temp <- rep(0,N)
for (i in 1:len) {
monte.carlo[(N + 1),i] <- mean(monte.carlo[c(1:N),i])
temp[] <- sort(monte.carlo[c(1:N),i])
monte.carlo[(N + 2),i] <- temp[0.95 * N] #upper
monte.carlo[(N + 3),i] <- temp[0.05 * N] #lower
}
# At this point we can just return the full monte carlo results if that's what the caller wants
if (get.monte.carlo) {
return(monte.carlo)
}
# Compute the local S index for each area.
# 0 if within confidence intervals, -1 or +1 otherwise
areas@data$Local.S <- ifelse(
areas$test <= monte.carlo[(N + 3),], -1,
ifelse( areas$test >= monte.carlo[(N + 2),], 1, 0 )
)
# Compute the global S Index
# Do this by adding up the number of times that the test data point is within the upper and lower bounds
# of the base data. (Could also do this using the local index calculated above)
S <-  sum(
(areas$test >= monte.carlo[(N + 3),]) & (areas$test <= monte.carlo[(N + 2),])
) / len
# Calculate excluding zero entries
# Same as above but also include the condition that there has to be a crime in the test data set
# as well as being within bounds.
S.nozero <- sum(
(areas$test >= monte.carlo[N + 3,]) & (areas$test <= monte.carlo[N + 2,]) & (areas$test > 0)
) / len
print(paste("S index: ",S, ". Excluding zeros: ",S.nozero))
# Store results ready to be returned when this is implemented as a function
areas@data$S = S # The s index, will be the same for each area (it is global)
areas@data$S.nozero = S.nozero
areas@data$mean <- monte.carlo[(N+1),1:len]       # Mean points in each area after resampling
areas@data$conf.upper <- monte.carlo[(N+2),1:len] # Upper confidence interval
areas@data$conf.lower <- monte.carlo[(N+3),1:len] # Lower confidence interval
return(areas)
}
#' Run Martin Andresen's Spatial Test
#'
#' @param basepoints The base point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param testpoints The test point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param areas The areas to aggregate the points to and run the test on. The type of this parameter changes the behaviour of the test:
#' - If a `SpatialPolygonsDataFrame` is provided, then the test will run using that geography (normal behaviour)
#' - If no `areas` parameter is provided, then the test will be run on a number of different regular grids of increasing size.
#' - If a list is provided, then the test will assume that this provides the number of cells across (columsm `areas[[1]]`) and down (rows, `areas[[2]]`) and will create a sigle regular grid that spans the extent of all of the input points with that many cells in it.
#' @param get.monte.carlo If true, then instead of returning the areas, return an array with the full results of all of the monte carlo runs in it. This is useful for debugging, or for plotting the results of each run. The array has N + 3 dimensions where N is the number of monte carlo iterations and the remaining three dimensions give the mean (N + 1), upper limit (N + 2), lower limit (N + 3).
#' @return The \code{areas} dataset with some new columns:
#'  Local.S - The S index for each area (either -1, 0, or 1)
#'   S - The global S index (which will be the same for each area)
#'   S.nozero - Same as 'S', but ignores areas without any crimes in them
#'   mean - The mean points in each area after resampling
#'   conf.upper - the Upper confidence interval for the test
#'   conf.lower - The lower confidence interval for the test
#' @examples
#' spatialtest(base.data, test.data, areas)
spatialtest <- function(basepoints, testpoints, areas, get.monte.carlo=FALSE) {
if (is(areas,"SpatialPolygonsDataFrame")) {
# The areas parameter is some polygons, so no need to do anything special.
# (This if statement could be removed, but is left here for clarity)
}
if (is.list(areas)) {
# The areas parameter is a list that provides the number of cells across and down. So now make a regular grid with these characteristics
# Make a raster first, then convert this to a SpatialPolygonsDataFrame
rast <- raster()
# Calculate extent of all the point (both crime and test data)
extent(rast) <- extent(gUnion(base.data, test.data))
# Now set the number of rows and columns
ncol(rast) <- areas[[1]]
nrow(rast) <- areas[[2]]
# Finish by converting to a SpatialPolygonsDataFrame
areas = SpatialPolygonsDataFrame(rast)
}
if (areas==NULL) {
# If areas is null the run the expanding cell algorithm
XXXX
}
# Aggregate the points to the area dataset
areas$base <- poly.counts(base.data, areas)
areas$test <- poly.counts(test.data,areas)
len <- length(areas) # The number of areas
tot <- sum(areas$base)    # The number of crimes
# An array to store the results of each monte carlo iteration temporarily.
# This is in long form (one row per crime). Dim 1=i, 2=sampled data (temp)
result <- array(0,c(2,tot))
# Generate the long form of the data for sampling - one row per crime
# (actually it's one crime per colum technically, but that doesn't really matter)
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
}
# Now run the Monte-Carlo simulation
# Store the results of each iteration in the monte.carlo array.
# N columns are for the simulations for each run, remaining three columns are for the mean
# of all runs and the upper and lower confidence intervals.
monte.carlo <- array(0,c((N + 3),len))
for (i in 1:N) { # (Could do this bit multi-process)
#resample (NOT SURE HOW THIS WORKS!!)
mc.samp <- trunc(runif(tot,min = 1,max = (tot + 1))) # Create a random number for each row
result[2,(1:tot)] <- result[1,mc.samp[1:tot]] # Store sampled data in result[2,] temporarily
for (j in 1:len) {
monte.carlo[i,j] <- sum(result[2,] == j) #compute reaggregate to areas
}
}
# Calculate the mean and confidence intervals for each area after the simulations
temp <- rep(0,N)
for (i in 1:len) {
monte.carlo[(N + 1),i] <- mean(monte.carlo[c(1:N),i])
temp[] <- sort(monte.carlo[c(1:N),i])
monte.carlo[(N + 2),i] <- temp[0.95 * N] #upper
monte.carlo[(N + 3),i] <- temp[0.05 * N] #lower
}
# At this point we can just return the full monte carlo results if that's what the caller wants
if (get.monte.carlo) {
return(monte.carlo)
}
# Compute the local S index for each area.
# 0 if within confidence intervals, -1 or +1 otherwise
areas@data$Local.S <- ifelse(
areas$test <= monte.carlo[(N + 3),], -1,
ifelse( areas$test >= monte.carlo[(N + 2),], 1, 0 )
)
# Compute the global S Index
# Do this by adding up the number of times that the test data point is within the upper and lower bounds
# of the base data. (Could also do this using the local index calculated above)
S <-  sum(
(areas$test >= monte.carlo[(N + 3),]) & (areas$test <= monte.carlo[(N + 2),])
) / len
# Calculate excluding zero entries
# Same as above but also include the condition that there has to be a crime in the test data set
# as well as being within bounds.
S.nozero <- sum(
(areas$test >= monte.carlo[N + 3,]) & (areas$test <= monte.carlo[N + 2,]) & (areas$test > 0)
) / len
print(paste("S index: ",S, ". Excluding zeros: ",S.nozero))
# Store results ready to be returned when this is implemented as a function
areas@data$S = S # The s index, will be the same for each area (it is global)
areas@data$S.nozero = S.nozero
areas@data$mean <- monte.carlo[(N+1),1:len]       # Mean points in each area after resampling
areas@data$conf.upper <- monte.carlo[(N+2),1:len] # Upper confidence interval
areas@data$conf.lower <- monte.carlo[(N+3),1:len] # Lower confidence interval
return(areas)
}
result2 <- spatialtest(
basepoints = base.data,
testpoints = test.data,
areas = list(20,30))
