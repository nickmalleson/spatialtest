# Make a raster first, then convert this to a SpatialPolygonsDataFrame
rast <- raster()
# Calculate extent of all the point (both crime and test data)
extent(rast) <- extent(base.data + test.data) # (could use gUnion(), but that's slower)
# Now set the number of rows and columns
ncols(rast) <- areas[[1]]
nrow(rast) <- areas[[2]]
values(rast)<-0 # Set all cell values to 0
# Finish by converting to a SpatialPolygonsDataFrame
areas = rasterToPolygons(rast)
}
if (areas==NULL) {
# If areas is null the run the expanding cell algorithm
XXXX
}
# Aggregate the points to the area dataset
areas$base <- poly.counts(base.data, areas)
areas$test <- poly.counts(test.data,areas)
len <- length(areas) # The number of areas
tot <- sum(areas$base)    # The number of crimes
# An array to store the results of each monte carlo iteration temporarily.
# This is in long form (one row per crime). Dim 1=i, 2=sampled data (temp)
result <- array(0,c(2,tot))
# Generate the long form of the data for sampling - one row per crime
# (actually it's one crime per colum technically, but that doesn't really matter)
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
}
# Now run the Monte-Carlo simulation
# Store the results of each iteration in the monte.carlo array.
# N columns are for the simulations for each run, remaining three columns are for the mean
# of all runs and the upper and lower confidence intervals.
monte.carlo <- array(0,c((N + 3),len))
for (i in 1:N) { # (Could do this bit multi-process)
#resample (NOT SURE HOW THIS WORKS!!)
mc.samp <- trunc(runif(tot,min = 1,max = (tot + 1))) # Create a random number for each row
result[2,(1:tot)] <- result[1,mc.samp[1:tot]] # Store sampled data in result[2,] temporarily
for (j in 1:len) {
monte.carlo[i,j] <- sum(result[2,] == j) #compute reaggregate to areas
}
}
# Calculate the mean and confidence intervals for each area after the simulations
temp <- rep(0,N)
for (i in 1:len) {
monte.carlo[(N + 1),i] <- mean(monte.carlo[c(1:N),i])
temp[] <- sort(monte.carlo[c(1:N),i])
monte.carlo[(N + 2),i] <- temp[0.95 * N] #upper
monte.carlo[(N + 3),i] <- temp[0.05 * N] #lower
}
# At this point we can just return the full monte carlo results if that's what the caller wants
if (get.monte.carlo) {
return(monte.carlo)
}
# Compute the local S index for each area.
# 0 if within confidence intervals, -1 or +1 otherwise
areas@data$Local.S <- ifelse(
areas$test <= monte.carlo[(N + 3),], -1,
ifelse( areas$test >= monte.carlo[(N + 2),], 1, 0 )
)
# Compute the global S Index
# Do this by adding up the number of times that the test data point is within the upper and lower bounds
# of the base data. (Could also do this using the local index calculated above)
S <-  sum(
(areas$test >= monte.carlo[(N + 3),]) & (areas$test <= monte.carlo[(N + 2),])
) / len
# Calculate excluding zero entries
# Same as above but also include the condition that there has to be a crime in the test data set
# as well as being within bounds.
S.nozero <- sum(
(areas$test >= monte.carlo[N + 3,]) & (areas$test <= monte.carlo[N + 2,]) & (areas$test > 0)
) / len
print(paste("S index: ",S, ". Excluding zeros: ",S.nozero))
# Store results ready to be returned when this is implemented as a function
areas@data$S = S # The s index, will be the same for each area (it is global)
areas@data$S.nozero = S.nozero
areas@data$mean <- monte.carlo[(N+1),1:len]       # Mean points in each area after resampling
areas@data$conf.upper <- monte.carlo[(N+2),1:len] # Upper confidence interval
areas@data$conf.lower <- monte.carlo[(N+3),1:len] # Lower confidence interval
return(areas)
}
result2 <- spatialtest(
basepoints = base.data,
testpoints = test.data,
areas = list(20,30)
)
#' Run Martin Andresen's Spatial Test
#'
#' @param basepoints The base point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param testpoints The test point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param areas The areas to aggregate the points to and run the test on. The type of this parameter changes the behaviour of the test:
#' - If a `SpatialPolygonsDataFrame` is provided, then the test will run using that geography (normal behaviour)
#' - If no `areas` parameter is provided, then the test will be run on a number of different regular grids of increasing size.
#' - If a list is provided, then the test will assume that this provides the number of cells across (columsm `areas[[1]]`) and down (rows, `areas[[2]]`) and will create a sigle regular grid that spans the extent of all of the input points with that many cells in it.
#' @param get.monte.carlo If true, then instead of returning the areas, return an array with the full results of all of the monte carlo runs in it. This is useful for debugging, or for plotting the results of each run. The array has N + 3 dimensions where N is the number of monte carlo iterations and the remaining three dimensions give the mean (N + 1), upper limit (N + 2), lower limit (N + 3).
#' @return The \code{areas} dataset with some new columns:
#'  Local.S - The S index for each area (either -1, 0, or 1)
#'   S - The global S index (which will be the same for each area)
#'   S.nozero - Same as 'S', but ignores areas without any crimes in them
#'   mean - The mean points in each area after resampling
#'   conf.upper - the Upper confidence interval for the test
#'   conf.lower - The lower confidence interval for the test
#' @examples
#' spatialtest(base.data, test.data, areas)
spatialtest <- function(basepoints, testpoints, areas, get.monte.carlo=FALSE) {
if (is(areas,"SpatialPolygonsDataFrame")) {
# The areas parameter is some polygons, so no need to do anything special.
# (This if statement could be removed, but is left here for clarity)
}
if (is.list(areas)) {
# The areas parameter is a list that provides the number of cells across and down.
# So now make a regular grid with these characteristics
# Make a raster first, then convert this to a SpatialPolygonsDataFrame
rast <- raster()
# Calculate extent of all the point (both crime and test data)
extent(rast) <- extent(base.data + test.data) # (could use gUnion(), but that's slower)
# Now set the number of rows and columns
ncol(rast) <- areas[[1]]
nrow(rast) <- areas[[2]]
values(rast)<-0 # Set all cell values to 0
# Finish by converting to a SpatialPolygonsDataFrame
areas = rasterToPolygons(rast)
}
if (areas==NULL) {
# If areas is null the run the expanding cell algorithm
XXXX
}
# Aggregate the points to the area dataset
areas$base <- poly.counts(base.data, areas)
areas$test <- poly.counts(test.data,areas)
len <- length(areas) # The number of areas
tot <- sum(areas$base)    # The number of crimes
# An array to store the results of each monte carlo iteration temporarily.
# This is in long form (one row per crime). Dim 1=i, 2=sampled data (temp)
result <- array(0,c(2,tot))
# Generate the long form of the data for sampling - one row per crime
# (actually it's one crime per colum technically, but that doesn't really matter)
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
}
# Now run the Monte-Carlo simulation
# Store the results of each iteration in the monte.carlo array.
# N columns are for the simulations for each run, remaining three columns are for the mean
# of all runs and the upper and lower confidence intervals.
monte.carlo <- array(0,c((N + 3),len))
for (i in 1:N) { # (Could do this bit multi-process)
#resample (NOT SURE HOW THIS WORKS!!)
mc.samp <- trunc(runif(tot,min = 1,max = (tot + 1))) # Create a random number for each row
result[2,(1:tot)] <- result[1,mc.samp[1:tot]] # Store sampled data in result[2,] temporarily
for (j in 1:len) {
monte.carlo[i,j] <- sum(result[2,] == j) #compute reaggregate to areas
}
}
# Calculate the mean and confidence intervals for each area after the simulations
temp <- rep(0,N)
for (i in 1:len) {
monte.carlo[(N + 1),i] <- mean(monte.carlo[c(1:N),i])
temp[] <- sort(monte.carlo[c(1:N),i])
monte.carlo[(N + 2),i] <- temp[0.95 * N] #upper
monte.carlo[(N + 3),i] <- temp[0.05 * N] #lower
}
# At this point we can just return the full monte carlo results if that's what the caller wants
if (get.monte.carlo) {
return(monte.carlo)
}
# Compute the local S index for each area.
# 0 if within confidence intervals, -1 or +1 otherwise
areas@data$Local.S <- ifelse(
areas$test <= monte.carlo[(N + 3),], -1,
ifelse( areas$test >= monte.carlo[(N + 2),], 1, 0 )
)
# Compute the global S Index
# Do this by adding up the number of times that the test data point is within the upper and lower bounds
# of the base data. (Could also do this using the local index calculated above)
S <-  sum(
(areas$test >= monte.carlo[(N + 3),]) & (areas$test <= monte.carlo[(N + 2),])
) / len
# Calculate excluding zero entries
# Same as above but also include the condition that there has to be a crime in the test data set
# as well as being within bounds.
S.nozero <- sum(
(areas$test >= monte.carlo[N + 3,]) & (areas$test <= monte.carlo[N + 2,]) & (areas$test > 0)
) / len
print(paste("S index: ",S, ". Excluding zeros: ",S.nozero))
# Store results ready to be returned when this is implemented as a function
areas@data$S = S # The s index, will be the same for each area (it is global)
areas@data$S.nozero = S.nozero
areas@data$mean <- monte.carlo[(N+1),1:len]       # Mean points in each area after resampling
areas@data$conf.upper <- monte.carlo[(N+2),1:len] # Upper confidence interval
areas@data$conf.lower <- monte.carlo[(N+3),1:len] # Lower confidence interval
return(areas)
}
result2 <- spatialtest(
basepoints = base.data,
testpoints = test.data,
areas = list(20,30)
)
#' Run Martin Andresen's Spatial Test
#'
#' @param basepoints The base point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param testpoints The test point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param areas The areas to aggregate the points to and run the test on. The type of this parameter changes the behaviour of the test:
#' - If a `SpatialPolygonsDataFrame` is provided, then the test will run using that geography (normal behaviour)
#' - If no `areas` parameter is provided, then the test will be run on a number of different regular grids of increasing size.
#' - If a list is provided, then the test will assume that this provides the number of cells across (columsm `areas[[1]]`) and down (rows, `areas[[2]]`) and will create a sigle regular grid that spans the extent of all of the input points with that many cells in it.
#' @param get.monte.carlo If true, then instead of returning the areas, return an array with the full results of all of the monte carlo runs in it. This is useful for debugging, or for plotting the results of each run. The array has N + 3 dimensions where N is the number of monte carlo iterations and the remaining three dimensions give the mean (N + 1), upper limit (N + 2), lower limit (N + 3).
#' @return The \code{areas} dataset with some new columns:
#'  Local.S - The S index for each area (either -1, 0, or 1)
#'   S - The global S index (which will be the same for each area)
#'   S.nozero - Same as 'S', but ignores areas without any crimes in them
#'   mean - The mean points in each area after resampling
#'   conf.upper - the Upper confidence interval for the test
#'   conf.lower - The lower confidence interval for the test
#' @examples
#' spatialtest(base.data, test.data, areas)
spatialtest <- function(basepoints, testpoints, areas, get.monte.carlo=FALSE) {
if (is(areas,"SpatialPolygonsDataFrame")) {
# The areas parameter is some polygons, so no need to do anything special.
# (This if statement could be removed, but is left here for clarity)
} else if (is.list(areas)) {
# The areas parameter is a list that provides the number of cells across and down.
# So now make a regular grid with these characteristics
# Make a raster first, then convert this to a SpatialPolygonsDataFrame
rast <- raster()
# Calculate extent of all the point (both crime and test data)
extent(rast) <- extent(base.data + test.data) # (could use gUnion(), but that's slower)
# Now set the number of rows and columns
ncol(rast) <- areas[[1]]
nrow(rast) <- areas[[2]]
values(rast)<-0 # Set all cell values to 0
# Finish by converting to a SpatialPolygonsDataFrame
areas = rasterToPolygons(rast)
} else if  (is.null(areas)) {
# If areas is null the run the expanding cell algorithm
XXXX <- 1
} else {
warning("I don't understand the 'areas' parameter")
return(-1)
}
# Aggregate the points to the area dataset
areas$base <- poly.counts(base.data, areas)
areas$test <- poly.counts(test.data,areas)
len <- length(areas) # The number of areas
tot <- sum(areas$base)    # The number of crimes
# An array to store the results of each monte carlo iteration temporarily.
# This is in long form (one row per crime). Dim 1=i, 2=sampled data (temp)
result <- array(0,c(2,tot))
# Generate the long form of the data for sampling - one row per crime
# (actually it's one crime per colum technically, but that doesn't really matter)
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
}
# Now run the Monte-Carlo simulation
# Store the results of each iteration in the monte.carlo array.
# N columns are for the simulations for each run, remaining three columns are for the mean
# of all runs and the upper and lower confidence intervals.
monte.carlo <- array(0,c((N + 3),len))
for (i in 1:N) { # (Could do this bit multi-process)
#resample (NOT SURE HOW THIS WORKS!!)
mc.samp <- trunc(runif(tot,min = 1,max = (tot + 1))) # Create a random number for each row
result[2,(1:tot)] <- result[1,mc.samp[1:tot]] # Store sampled data in result[2,] temporarily
for (j in 1:len) {
monte.carlo[i,j] <- sum(result[2,] == j) #compute reaggregate to areas
}
}
# Calculate the mean and confidence intervals for each area after the simulations
temp <- rep(0,N)
for (i in 1:len) {
monte.carlo[(N + 1),i] <- mean(monte.carlo[c(1:N),i])
temp[] <- sort(monte.carlo[c(1:N),i])
monte.carlo[(N + 2),i] <- temp[0.95 * N] #upper
monte.carlo[(N + 3),i] <- temp[0.05 * N] #lower
}
# At this point we can just return the full monte carlo results if that's what the caller wants
if (get.monte.carlo) {
return(monte.carlo)
}
# Compute the local S index for each area.
# 0 if within confidence intervals, -1 or +1 otherwise
areas@data$Local.S <- ifelse(
areas$test <= monte.carlo[(N + 3),], -1,
ifelse( areas$test >= monte.carlo[(N + 2),], 1, 0 )
)
# Compute the global S Index
# Do this by adding up the number of times that the test data point is within the upper and lower bounds
# of the base data. (Could also do this using the local index calculated above)
S <-  sum(
(areas$test >= monte.carlo[(N + 3),]) & (areas$test <= monte.carlo[(N + 2),])
) / len
# Calculate excluding zero entries
# Same as above but also include the condition that there has to be a crime in the test data set
# as well as being within bounds.
S.nozero <- sum(
(areas$test >= monte.carlo[N + 3,]) & (areas$test <= monte.carlo[N + 2,]) & (areas$test > 0)
) / len
print(paste("S index: ",S, ". Excluding zeros: ",S.nozero))
# Store results ready to be returned when this is implemented as a function
areas@data$S = S # The s index, will be the same for each area (it is global)
areas@data$S.nozero = S.nozero
areas@data$mean <- monte.carlo[(N+1),1:len]       # Mean points in each area after resampling
areas@data$conf.upper <- monte.carlo[(N+2),1:len] # Upper confidence interval
areas@data$conf.lower <- monte.carlo[(N+3),1:len] # Lower confidence interval
return(areas)
}
result2 <- spatialtest(
basepoints = base.data,
testpoints = test.data,
areas = list(20,30)
)
?CRS()
CRS(areas) <- proj4string(base.data)
proj4string(areas) <- CRS(base.data)
base.data
CRS(base.data)
prproj4string(areas) <- CRS(base.data)
proj4string(base.data)
proj4string(areas) <- proj4string(base.data)
rast <- raster()
proj4string(rast) <- proj4string(base.data)
#' Run Martin Andresen's Spatial Test
#'
#' @param basepoints The base point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param testpoints The test point dataset. This is expected to be a SpatialPointsDataFrame, but might work with other types of objects
#' @param areas The areas to aggregate the points to and run the test on. The type of this parameter changes the behaviour of the test:
#' - If a `SpatialPolygonsDataFrame` is provided, then the test will run using that geography (normal behaviour)
#' - If no `areas` parameter is provided, then the test will be run on a number of different regular grids of increasing size.
#' - If a list is provided, then the test will assume that this provides the number of cells across (columsm `areas[[1]]`) and down (rows, `areas[[2]]`) and will create a sigle regular grid that spans the extent of all of the input points with that many cells in it.
#' @param get.monte.carlo If true, then instead of returning the areas, return an array with the full results of all of the monte carlo runs in it. This is useful for debugging, or for plotting the results of each run. The array has N + 3 dimensions where N is the number of monte carlo iterations and the remaining three dimensions give the mean (N + 1), upper limit (N + 2), lower limit (N + 3).
#' @return The \code{areas} dataset with some new columns:
#'  Local.S - The S index for each area (either -1, 0, or 1)
#'   S - The global S index (which will be the same for each area)
#'   S.nozero - Same as 'S', but ignores areas without any crimes in them
#'   mean - The mean points in each area after resampling
#'   conf.upper - the Upper confidence interval for the test
#'   conf.lower - The lower confidence interval for the test
#' @examples
#' spatialtest(base.data, test.data, areas)
spatialtest <- function(basepoints, testpoints, areas, get.monte.carlo=FALSE) {
if (is(areas,"SpatialPolygonsDataFrame")) {
# The areas parameter is some polygons, so no need to do anything special.
# (This if statement could be removed, but is left here for clarity)
} else if (is.list(areas)) {
# The areas parameter is a list that provides the number of cells across and down.
# So now make a regular grid with these characteristics
# Make a raster first, then convert this to a SpatialPolygonsDataFrame
rast <- raster()
proj4string(rast) <- proj4string(base.data)
# Calculate extent of all the point (both crime and test data)
extent(rast) <- extent(base.data + test.data) # (could use gUnion(), but that's slower)
# Now set the number of rows and columns
ncol(rast) <- areas[[1]]
nrow(rast) <- areas[[2]]
values(rast)<-0 # Set all cell values to 0
# Finish by converting to a SpatialPolygonsDataFrame and setting the CRS to match the points
areas = rasterToPolygons(rast)
} else if  (is.null(areas)) {
# If areas is null the run the expanding cell algorithm
XXXX <- 1
} else {
warning("I don't understand the 'areas' parameter")
return(-1)
}
# Aggregate the points to the area dataset
areas$base <- poly.counts(base.data, areas)
areas$test <- poly.counts(test.data,areas)
len <- length(areas) # The number of areas
tot <- sum(areas$base)    # The number of crimes
# An array to store the results of each monte carlo iteration temporarily.
# This is in long form (one row per crime). Dim 1=i, 2=sampled data (temp)
result <- array(0,c(2,tot))
# Generate the long form of the data for sampling - one row per crime
# (actually it's one crime per colum technically, but that doesn't really matter)
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
}
# Now run the Monte-Carlo simulation
# Store the results of each iteration in the monte.carlo array.
# N columns are for the simulations for each run, remaining three columns are for the mean
# of all runs and the upper and lower confidence intervals.
monte.carlo <- array(0,c((N + 3),len))
for (i in 1:N) { # (Could do this bit multi-process)
#resample (NOT SURE HOW THIS WORKS!!)
mc.samp <- trunc(runif(tot,min = 1,max = (tot + 1))) # Create a random number for each row
result[2,(1:tot)] <- result[1,mc.samp[1:tot]] # Store sampled data in result[2,] temporarily
for (j in 1:len) {
monte.carlo[i,j] <- sum(result[2,] == j) #compute reaggregate to areas
}
}
# Calculate the mean and confidence intervals for each area after the simulations
temp <- rep(0,N)
for (i in 1:len) {
monte.carlo[(N + 1),i] <- mean(monte.carlo[c(1:N),i])
temp[] <- sort(monte.carlo[c(1:N),i])
monte.carlo[(N + 2),i] <- temp[0.95 * N] #upper
monte.carlo[(N + 3),i] <- temp[0.05 * N] #lower
}
# At this point we can just return the full monte carlo results if that's what the caller wants
if (get.monte.carlo) {
return(monte.carlo)
}
# Compute the local S index for each area.
# 0 if within confidence intervals, -1 or +1 otherwise
areas@data$Local.S <- ifelse(
areas$test <= monte.carlo[(N + 3),], -1,
ifelse( areas$test >= monte.carlo[(N + 2),], 1, 0 )
)
# Compute the global S Index
# Do this by adding up the number of times that the test data point is within the upper and lower bounds
# of the base data. (Could also do this using the local index calculated above)
S <-  sum(
(areas$test >= monte.carlo[(N + 3),]) & (areas$test <= monte.carlo[(N + 2),])
) / len
# Calculate excluding zero entries
# Same as above but also include the condition that there has to be a crime in the test data set
# as well as being within bounds.
S.nozero <- sum(
(areas$test >= monte.carlo[N + 3,]) & (areas$test <= monte.carlo[N + 2,]) & (areas$test > 0)
) / len
print(paste("S index: ",S, ". Excluding zeros: ",S.nozero))
# Store results ready to be returned when this is implemented as a function
areas@data$S = S # The s index, will be the same for each area (it is global)
areas@data$S.nozero = S.nozero
areas@data$mean <- monte.carlo[(N+1),1:len]       # Mean points in each area after resampling
areas@data$conf.upper <- monte.carlo[(N+2),1:len] # Upper confidence interval
areas@data$conf.lower <- monte.carlo[(N+3),1:len] # Lower confidence interval
return(areas)
}
result2 <- spatialtest(
basepoints = base.data,
testpoints = test.data,
areas = list(20,30)
)
rast <- raster()
proj4string(rast) <- proj4string(base.data)
extent(rast) <- extent(base.data + test.data) # (could use gUnion(), but that's slower)
areas = list(20,30)
ncol(rast) <- areas[[1]]
nrow(rast) <- areas[[2]]
values(rast)<-0 # Set all cell values to 0
# Finish by converting to a SpatialPolygonsDataFrame and setting the CRS to match the points
rast
areas
areas = rasterToPolygons(rast)
areas
areas$base <- poly.counts(base.data, areas)
areas$test <- poly.counts(test.data,areas)
len <- length(areas) # The number of areas
tot <- sum(areas$base)    # The number of crimes
# Create the shading scheme:
shades <- shading(c(0,1), cols = c("#d8b365", "#f5f5f5", "#5ab4ac"))
# Create the choropleth map, using the shading scheme defined above
choropleth(result2, result2$Local.S, shading = shades, border=NULL)
# Add the lengend. For some reason choro.legend doesn't work
#choro.legend(px=480000, py=5462000, shades )
legend(x=480000, y=5462000, c("-1", "0", "+1"), col = c("#d8b365", "#f5f5f5", "#5ab4ac"), pch=15)
result <- array(0,c(2,tot))
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
}
i<-1
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
start:end
ct <- 0 # counter
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
i<-2
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
result[1,c(start:end)] <- i
ct <- end
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
# XXXX ERROR HERE
result[1,c(start:end)] <- i
# XXXX ERROR HERE
ct <- end
}
ct <- 0 # counter
for (i in 1:len) {
start <- ct + 1
end <- start + areas$base[i] - 1 # Number of crimes in area i
# XXXX ERROR HERE
result[1,c(start:end)] <- i
print(paste(start," ", end, " ",i))
# XXXX ERROR HERE
ct <- end
}
