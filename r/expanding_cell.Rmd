---
title: "Multiscale Spatial Error Assessment"
author: "Nick Malleson"
date: '`r format(Sys.time(), "%d %B, %Y (%H:%M)")`'
output:
  html_document: 
    toc: yes
    pandoc_args: [
      "+RTS", "-K64m",
      "-RTS"
    ]
  pdf_document:
    fig_crop: no
    highlight: kate
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
fontsize: 10pt
---

```{r initialise, echo=FALSE, message=FALSE, warning=FALSE}
setwd('~/research_not_syncd/git_projects/spatialtest/r/')

library(GISTools)
#library(rgeos)    # For things like gIntersects
library(rgdal)     # For reading shapefiles
library(raster)    # For creating regular grids
#library(plyr)     # For counting and aggregating
#library(tmap)     # For thematic maps
library(classInt) # Jenks natural breaks
#library(png)      # For loading pngs after they have been written
#library(grid)     # so that they can be embedded in knitted documents
#library(spdep)    # For doing the spatial regression, contiguity matrices, etc.
#library(GWmodel)  # For geographically weighted regression (GWR)
#library(MASS)     # For stepwise regression (stepAIC())
#library(pander)   # For printing tables nicely
#library(MVN)      # For testing for multivariate normality (MVN)
#library(RColorBrewer) # For making nice colour themes
library(hydroGOF)   # Has an rmse() function


```



<img style="float:right; width:50%"
src="http://www.geog.leeds.ac.uk/courses/other/programming/practicals/general/modelling/validation/multiscale-code/images/figure2.jpg"
/>

# Multiscale Spatial Error Assessment

This is the R implementation of the Multiscale Spatial Error Assessment method (aka [Multiscale Validation](http://www.geog.leeds.ac.uk/courses/other/programming/practicals/general/modelling/validation/multiscale-code/2.html)). 

The aim of the method is to take two point-patterns, iteratively aggregate the points to cells of increasing size, and calculate the error between the two data sets at the different grid resoultions. See the right images for an example (from  [here](http://www.geog.leeds.ac.uk/courses/other/programming/practicals/general/modelling/validation/multiscale-code/2.html)).

Ultimately the method will be converted into a (suite of) function(s) and integrated with the Andresen's S index.

The method has has been used in the following paper:

Malleson, N., A. Heppenstall, L. See, A. Evans (2013) Using an agent-based crime simulation to predict the effects of urban regeneration on individual household burglary risk. _Environment and Planning B: Planning and Design._ 40(3) 405-426. Available [here](http://www.envplan.com/abstract.cgi?id=b38057) and [here](http://nickmalleson.co.uk/wp-content/uploads/2013/05/EPB-V6-forBlog.pdf) (if you don't have access to the journal)

Thanks to Lex Comber and Chris Brunsdon for their excellent book 'R for Spatial Analysis and Mapping'. I got most of the R GIS stuff from there.

Brunsdon, C and Comber, L (2015) _An Introduction to R for Spatial Anaysis and Mapping_. Sage

<img style="float:right; width:40%"
src="http://www.geog.leeds.ac.uk/courses/other/programming/practicals/general/modelling/validation/multiscale-code/images/graph.jpg"
/>

## Configuration

Configure the script here. (Un)comment or edit lines as appropriate to change the data used and the parameters for the method.

```{r config}
N <- 10 # The number of cell resolutions to run. (1=just one big cell surrounding all of the data)

# For the basic test:
#datasource <- "../data/basic_test/" # The folder with the shapefiles

# Some London data:
#datasource <- "../data/london_burglary/" 

# Some Vancouver data:
datasource <- "../data/vancouver_all/"

base.layer <- "points1" # THe name of the base dataset
test.layer <- "points2" # THe name of the test dataset
#areas.layer <- "areas"  # The polygon boundary file

# multiprocess <- FALSE # Whether to run the simulation using multiple cores
```
 
## Read Data

```{r readData, message=FALSE}

# Read some data

#areas <- readOGR(ds = datasource, layer=areas.layer)
base.data <- readOGR(ds = datasource, layer=base.layer)
test.data <- readOGR(ds = datasource, layer=test.layer)


#plot(areas)
plot(base.data, col="blue")
plot(test.data, col="red",add=T)

```

## Run the Error Assessment Method

The method works as follows:

  1. Generate the grids.
    a. Begin by creating one large grid over the entire study area
    a. Label each grid with a number (e.g. 'a')
    a. Split the grid into four and give each cell a new label (e.g. 'aa', 'ab', 'ac', 'ad')
    a. Repeat (a-c) until a threshold (N) has been reached
    
  1. Aggregate the points to each of the smallest cells.
  
  1. Calculate the aggregate number of points in each of the larger cells using the labels (this is more efficient as it doesn't require the points to be re-aggregated each time.)
  
  1. Map and graph the results
  
  
  XXXX HERE - CONVERT TO A FUNCTION

```{r runMethod}

bb <- bbox(base.data + test.data) # A bounding box around all points

# Store all grids (data frames) in a big long list
results <- list()
# Also remember some other things that are useful later
cell.areas <- c() # The area of the cells
num.cells <- c()  # The number of cells in each iteration

# Create the grids - adapted from Brunsdon & Comber (2015, p150)
for (i in seq(1,N)) {
  # Cell size is the total width divided by the number of cells to draw so far (i)
  cell.width <- (bb[1,2] - bb[1,1]) / i
  cell.height <- (bb[2,2] - bb[2,1]) / i
  cell.areas <- c(cell.areas, (cell.width * cell.height) ) # Also remember the cell area for later
  
  # For each resolution, repeat a few times by slightly shifting each grid in N, E, S, W to lessen the impact of MAUP
  # NOT IMPLEMENTED YET. SLIGHTLY TRICKY BECAUSE GRID WILL NEED TO BE BIGGER OTHERWISE SOME POINTS WILL NOT BE COVERED
  for (shift in 1:1) {
    # Need to calculate the centre of the bottom-right cell
    if (shift==1) { # This is the grid with no shifting (i.e. it fits perfectly over the study area)
      centre.x <- bb[1,1] + ( cell.width / 2 )
      centre.y <- bb[2,1] + ( cell.height / 2 )
    }
    # .. WILL IMPLEMENT REMAINING SHIFTS HERE
    
    # Create a grid  
    grd <- GridTopology(
      cellcentre.offset = c(centre.x, centre.y), # No offset, the grid will just cover all the points
      cellsize = c(cell.width, cell.height),
      cells.dim = c(i,i)
    )
    
    number.of.cells <- i * i
    num.cells <- c(num.cells, number.of.cells) # Remember the number of cells in this iteration
    
    # Convert the grid into a SpatialPolygonsDataFrame
    spdf <- SpatialPolygonsDataFrame(
      as.SpatialPolygons.GridTopology(grd),
      data = data.frame(c(1:number.of.cells)),
      match.ID = FALSE
    )
    proj4string(spdf) <- proj4string(test.data)
    names(spdf) <- "CellID" # Name the column
    
    # Aggregat the points
    spdf@data$base <- poly.counts(base.data, spdf)
    spdf@data$test <- poly.counts(test.data, spdf)
    
    # Calculate percentages of points in each area (might be useful)
    spdf@data$base.prop <- 100 * spdf@data$base / sum(spdf@data$base )
    spdf@data$test.prop <- 100 * spdf@data$test / sum(spdf@data$test )
    
    # Calculate the errors 
    
    # Difference in the number of points
    spdf@data$diff <- spdf@data$base - spdf@data$test
    # Absolute difference
    spdf@data$abs.diff <- abs(spdf@data$base - spdf@data$test)
    
    # Difference in proportions
    spdf@data$abs.prop.diff <- spdf@data$base.prop - spdf@data$test.prop
    
    # Store this result
    results[[i]] <- spdf
  
  } # for shifting grids
  
} # for cell sizes
  
```

## Map the results

For a sanity check: map the total number of base and test points for some different grids

```{r map.totals }
par(mfrow=c(2,4))

#plot(results[[length(results)]])
#points(base.data)
for (i in 4:1) {
  index <- round(length(results) / i )
  choropleth(results[[index]], results[[index]]@data$base, main=paste("Base points",i))
}

#plot(results[[length(results)]])
#points(test.data)
for (i in 4:1) {
  index <- round(length(results) / i )
  choropleth(results[[index]], results[[index]]@data$test, main=paste("Test points",i))
}
```

# Now map the difference in the proportions

```{r map.abs.prop.diff}
par(mfrow=c(2,2))
for (i in 4:1) {
  index <- round(length(results) / i )
  choropleth(results[[index]], results[[index]]@data$abs.prop.diff, main=paste("Absoulte difference in proportions",i))
}
```

Finally make a fuzzy grid of all results

```{r map.abs.prop.diff.fuzzy}
par(mfrow=c(1,1))

statistic <- "abs.prop.diff" # The statistic to map
last.result <- results[[length(results)]] # Convenience for list result generated (the smallest grid)

# Shading
shades <- shading(
    classIntervals(last.result@data$abs.prop.diff, n = 8, style = 'kmeans')$brks,
    cols=add.alpha(brewer.pal(9,'Reds'), (1/N)) 
)

choropleth(
  last.result, last.result@data$abs.prop.diff,
  shading = shades,
  main="Fuzzy Absoulte difference in proportions",
  lty=0
  )

for ( index in 1:(N-1)) {
  choropleth( results[[index]], results[[index]]@data$abs.prop.diff,
  shading = shades,
  lty=0,
  add=TRUE)
}

```

## Calculate and graph the errors

Calculate the following errors:

  - **Residual Sum of Squares (RSS)** (This is easy, just add up the square of the differences)
  - **R-Squared**
  - **Root Mean Square Error (RMSE)**
 
 And then graph them using two difference x axes:
 
  - The number of cells used
  - The square area of an individual cell (smallest cells first)

```{r graphError }

# Go through all of the results and calculate errors

rss <- c() # Residual sum of squares
r.squared <- c()
rmse <- c()


for (i in 1:length(results)) {
  
  the.result <- results[[i]]@data # Convenience for referring to the current result we're looking at
  #the.result.nozero <- results[[i]]@data # Convenience for referring to the current result we're looking at
 
  # RSS 
  rss <- c(rss, sum( ( the.result$base - the.result$test )**2 ))
  # R squared
  r.squared <- c(r.squared, summary(lm(the.result$base ~ the.result$test, data=the.result))$r.squared )
  # RMSE
  rmse <- c(rmse, rmse(the.result$base, the.result$test) )
  
}

par(mfrow=c(2,3))

plot(x=num.cells, y=rss, type='o', main="RSS", xlab="Number of cells")
plot(x=num.cells, y=r.squared, type='o', main="R-Squared", xlab="Number of cells")
plot(x=num.cells, y=rmse, type='o', main="RMSE", xlab="Number of cells")
plot(x=rev(cell.areas), y=rss, type='o', main="RSS", xlab="Square area of a cell")
plot(x=rev(cell.areas), y=r.squared, type='o', main="R-Squared", xlab="Square area of a cell")
plot(x=rev(cell.areas), y=rmse, type='o', main="RMSE", xlab="Square area of a cell")


```

XXXX HER